version 1.0

workflow test_HTAN_meta {
	input {
		###### count_matrix.csv generated by cumulus-cellranger ######
		String? cumulus_count_matrix

		###### count_matrix.csv provided by user (not running cumulus-cellranger) ######
		String? user_count_matrix

		###### whether the user runs cumulus-cellranger ######
		Boolean run_cumulus_cellranger

		###### sample_sheet specified ######
		File sample_sheet

		###### output folder of the HTAN meta files ######
		String output_dir

		###### job resource #####
		Int manifest_num_cpu
		String manifest_memory
		Int manifest_disk_space
		String sctk_docker = "campbio/sctk_qc:2.2.0"


		###### The HTAN level2 manifest file ######
		String cellranger_version
		String? genome_reference_name

		###### output folder of SCTK-QC pipeline ######
		String sctk_output_dir
		File tmp

	}

	call generate_level2_meta {
		input: 
			cumulus_count_matrix = cumulus_count_matrix,
			user_count_matrix = user_count_matrix,
			sample_sheet = sample_sheet,
			output_dir = output_dir,
			tmp = tmp,
			run_cumulus_cellranger = run_cumulus_cellranger,
			num_cpu = manifest_num_cpu,
			memory = manifest_memory,
			disk_space = manifest_disk_space,
			workflow_version = cellranger_version,
			workflow_link = "https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/what-is-cell-ranger",
			genome_reference_name = genome_reference_name,
			sctk_docker = sctk_docker
	}


	call generate_level3_meta {
		input: 
			level2_meta = generate_level2_meta.level2_manifest,
			sample_sheet = sample_sheet,
			sctk_output_dir = sctk_output_dir,
			output_dir = output_dir,
			num_cpu = manifest_num_cpu,
			memory = manifest_memory,
			disk_space = manifest_disk_space,
			sctk_docker = sctk_docker,
			tmp = generate_level2_meta.l2_tmp
	}

	call generate_level4_meta {
		input: 
			level3_meta = generate_level3_meta.level3_manifest,
			sample_sheet = sample_sheet,
			sctk_output_dir = sctk_output_dir,
			output_dir = output_dir,
			num_cpu = manifest_num_cpu,
			memory = manifest_memory,
			disk_space = manifest_disk_space,
			sctk_docker = sctk_docker,
			tmp = generate_level3_meta.l3_tmp
	}
	

	output {
		#String? manifest_path = "~{output_dir}"
		#Array[String] level2_study = generate_level2_meta.study
		File? level2_manifest = generate_level2_meta.level2_manifest
		File? level3_study = generate_level3_meta.level3_manifest
		#Array[Map[String, String]] level3_manifest = generate_level3_meta.level3_manifest
		File? level4_manifest = generate_level4_meta.level4_manifest
	}

}

task generate_level2_meta {
	input {
		String? cumulus_count_matrix
		String? user_count_matrix
		File sample_sheet
		String output_dir
		Boolean run_cumulus_cellranger
		Int num_cpu
		String memory
		Int disk_space
		String workflow_version
		String workflow_link = "https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/what-is-cell-ranger"
		String? genome_reference_name
		File tmp
		String sctk_docker = "campbio/sctk_qc:2.2.0"

	}

	command {
		echo $(date +%T)
		gsutil -q -m cp '~{sample_sheet}' .
		echo "Done copying the sample sheet"
		echo $(date +%T)

		echo "The output folder of HTAN level2 manifest file is:"
		echo ${output_dir}

		python3 <<CODE
		import pandas as pd
		import numpy as np
		import os
		import hashlib
		import re
		from datetime import datetime

		def print_time():
			dateTimeObj = datetime.now()
			return dateTimeObj

		print("Start generating level2 manifest file")


		def calculate_md5sum(path):
			os.system("gsutil hash -h %s > md5sum.txt" % (path))
			f = open('md5sum.txt', 'r')

			for line in f:
				line = line.strip()
				line = line.split()
				if line[1] == '(md5):':
					md5sum = line[2]
					return md5sum

		print("Start copying the count_matrix.csv")
		print(print_time())
		### copy count_matrix.csv and sample_sheet
		if '~{run_cumulus_cellranger}' == 'true':
			count_matrix_path = "~{cumulus_count_matrix}"
		else:
			count_matrix_path = "~{user_count_matrix}"

		cp_code = "gsutil -q -m cp %s ." % (count_matrix_path)
		print(cp_code)
		os.system(cp_code)
		#cp_code = "gsutil -q -m cp %s ." % (sample_sheet)
		print("Done copying the count_matrix.csv file")
		print(print_time())


		### start processing level2 HTAN manifest files
		mat_file = os.path.basename(count_matrix_path)
		sample_sheet_file = os.path.basename("~{sample_sheet}")

		samplesheet = pd.read_csv(sample_sheet_file)
		count_csv = pd.read_csv(mat_file)

		samplesheet['HTAN_patient_ID'] = samplesheet['HTAN_Parent_Biospecimen_ID'].apply(lambda x: "_".join(x.split("_")[:2]))
		count_csv['FastqsFolder'] = samplesheet.loc[count_csv.index, 'Flowcell']
		count_csv['FastqsFolder'] = count_csv['FastqsFolder'] + "/" + count_csv['Sample']
		count_csv['Genome_Annotation_link'] = samplesheet.loc[count_csv.index, 'Genome_Annotation']
		count_csv['Genome_Reference_link'] = samplesheet.loc[count_csv.index, 'Reference']

		print(count_csv)
		print(count_csv['FastqsFolder'])

		#### localize the bam and fastq files to compute checkSum
		print("Start generate checkSum for the bam and fastqs files")
		print(print_time())
		count_csv['Bam tendig checkSum'] = ""
		count_csv['Fastqs tendig Checksum'] = ""
		count_csv['checkSum'] = ""
		for i in (count_csv.index):
			bam = count_csv.loc[i, "Bam"]
			sample = count_csv.loc[i, "Sample"]

			print(sample)
			print(bam)
			print(os.path.basename(bam))

			bam_md5 = calculate_md5sum(bam)
			print(bam_md5)
			count_csv.loc[i, 'checkSum'] = bam_md5 #
			count_csv.loc[i, 'Bam tendig checkSum'] = str(int(bam_md5, base=16))[-10:]

			fastq_dir = count_csv.loc[i, "FastqsFolder"]
			fastq_md5s = []
			os.system('gsutil ls %s > fastqs.txt' % (fastq_dir))
			with open('fastqs.txt', 'r') as f:
				for line in f:
					fastq = line.strip()
					if (bool(re.match(r"[\w\d-]+_R2_[\w\d]+.fastq.gz", os.path.basename(fastq)))):
						fastq_md5 = calculate_md5sum(fastq)
						fastq_md5s.append(str(int(fastq_md5, base=16))[-10:])
			print(fastq_md5s)
			count_csv.loc[i, 'Fastqs tendig Checksum'] = fastq_md5s


		#print("Generating checkSum for bam")
		print(print_time())
		count_csv['HTAN Patient ID'] = samplesheet.loc[count_csv.index, 'HTAN_patient_ID']
		count_csv['HTAN Biospecimen ID'] = samplesheet.loc[count_csv.index, 'HTAN_Parent_Biospecimen_ID'] 

		#tendig_checkSum = count_csv['checkSum'].apply(lambda x: str(int(x, base=16))[-10:])
		count_csv['HTAN Data File ID'] = count_csv['HTAN Patient ID'] + "_" + count_csv['Bam tendig checkSum']
		print(print_time())


		#### generate HTAN Parent Data File ID (fastq files) for level2 metadatq
		print("Generating checkSum for fastqs")
		print(print_time())
		for i in (count_csv.index):
			fastqs_256 = count_csv.loc[i, 'Fastqs tendig Checksum']
			patient_id = count_csv.loc[i, 'HTAN Patient ID']
			htan_parent_data_id = [patient_id + "_" + x for x in fastqs_256]
			count_csv.loc[i, "HTAN Parent Data File ID"] = ",".join(htan_parent_data_id)		
		print(print_time())

		### create place holder of level2 metadata
		x = np.array([[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]])
		c = ['Component',
			'Filename',
			'File Format',
			'HTAN Parent Data File ID',
			'HTAN Data File ID',
			'scRNAseq Workflow Type',
			'Workflow Version',
			'scRNAseq Workflow Parameters Description',
			'Workflow Link',
			'Genomic Reference',
			'Genomic Reference URL',
			'Genome Annotation URL',
			'Checksum',
			'Whitelist Cell Barcode File Link',
			'Cell Barcode Tag',
			'UMI Tag', 'Applied Hard Trimming', 'HTAN Biospecimen ID']

		l2_csv = pd.DataFrame(x, index = c)
		l2_csv = l2_csv.transpose()

		l2_csv['Filename'] = count_csv['Bam']
		l2_csv['Genome Annotation URL'] = count_csv['Genome_Annotation_link']
		l2_csv['Genomic Reference URL'] = count_csv['Genome_Reference_link']
		l2_csv['HTAN Data File ID'] = count_csv['HTAN Data File ID']
		l2_csv['HTAN Parent Data File ID'] = count_csv['HTAN Parent Data File ID']
		l2_csv['Checksum'] = count_csv['checkSum']
		l2_csv['Component'] = "ScRNA-seqLevel2"
		l2_csv['File Format'] = "bam"
		l2_csv['scRNAseq Workflow Type'] = "CellRanger"
		l2_csv['Whitelist Cell Barcode File Link'] = "https://github.com/10XGenomics/cellranger/raw/master/lib/python/cellranger/barcodes/3M-february-2018.txt.gz"
		l2_csv['Cell Barcode Tag'] = "CB"
		l2_csv['UMI Tag'] = "UB"
		l2_csv['Applied Hard Trimming'] = "No"
		l2_csv['Workflow Version'] = "~{workflow_version}"
		l2_csv['Workflow Link'] = "~{workflow_link}"
		l2_csv['Genomic Reference'] = "~{genome_reference_name}"
		l2_csv['HTAN Biospecimen ID'] = count_csv['HTAN Biospecimen ID']

		print("check the dim of l2_csv")
		print(l2_csv.shape)

		l2_csv.to_csv("HTAN_level2_manifest.csv",sep=",", index=False, header=True)
		os.system("gsutil -q -m cp HTAN_level2_manifest.csv ~{output_dir}")
		print("Output level2 manifest file done")

		CODE
		#gsutil -q -m cp HTAN_level2_manifest.csv '~{output_dir}' .
		#echo "Done copying the level2 manifest file outside python script"
		ls ./* >> level2_ls.txt
	}

	output {

		File? l2_tmp = "./level2_ls.txt"
		File? level2_manifest = "~{output_dir}/HTAN_level2_manifest.csv"
	}

	runtime {
		# Use this container, pull from DockerHub   
		docker: sctk_docker
		cpu: num_cpu
		memory: memory
		disks: "local-disk ~{disk_space} HDD"
		bootDiskSizeGb: 50
		preemptible: 2    
	} 
}

task generate_level3_meta {
	input {
		File? level2_meta
		File sample_sheet
		String sctk_output_dir
		String output_dir
		Int num_cpu
		String memory
		Int disk_space
		String sctk_docker = "campbio/sctk_qc:2.2.0"
		File? tmp
	}

	command {
		echo $(date +%T)
		gsutil -q -m cp '~{sample_sheet}' .
		echo "Done copying the sample sheet"
		echo $(date +%T) 
		gsutil -q -m cp '~{level2_meta}' .
		echo "Done copying the level2 manifest file"

		python3 <<CODE
		import pandas as pd
		import numpy as np
		import os
		import hashlib
		import re
		from datetime import datetime

		def calculate_md5sum(path):
			os.system("gsutil hash -h %s > md5sum.txt" % (path))
			f = open('md5sum.txt', 'r')

			for line in f:
				line = line.strip()
				line = line.split()
				if line[1] == '(md5):':
					md5sum = line[2]
					return md5sum

		def print_time():
			dateTimeObj = datetime.now()
			return dateTimeObj

		print("Start generating level3 manifest file")
		print(print_time())

		sp = os.path.basename('~{sample_sheet}')
		lp = os.path.basename('~{level2_meta}')

		samplesheet = pd.read_csv(sp)
		l2_csv = pd.read_csv(lp)

		### read all level3 meta files generated by SCTK-QC
		print("Start loading all level3 meta data generated by SCTK-QC")
		print(print_time())
		m3_list = dict()
		for s in samplesheet["Sample"]:
			fp = "~{sctk_output_dir}/" + s + "_QCOut"
			print(fp)

			os.system("mkdir %s" % (s))
			fn = fp + "/" + "level3Meta.csv"
			os.system("gsutil -q -m cp %s ./%s" % (fn, s))
			f = pd.read_csv("%s/level3Meta.csv" % (s), index_col = 0)
			m3_list[s] = f

		print(m3_list.keys())
		m3 = pd.concat(m3_list)
		m3
		print(print_time())

		samplesheet = samplesheet.set_index('Sample')
		m3 = m3.set_index('SAMPLE')


		samplesheet['HTAN_patient_ID'] = samplesheet['HTAN_Parent_Biospecimen_ID'].apply(lambda x: "_".join(x.split("_")[:2]))
		m3['HTAN_patient_ID'] = samplesheet.loc[m3.index, 'HTAN_patient_ID']
		m3['HTAN_BIOSPECIMEN_ID'] = samplesheet.loc[m3.index, 'HTAN_Parent_Biospecimen_ID'].values

		l2_csv['HTAN_patient_ID'] = l2_csv['HTAN Data File ID'].apply(lambda x: "_".join(x.split("_")[:2]))
		l2_csv = l2_csv.set_index('HTAN_patient_ID')

		### generate HTAN Parent File ID
		m3['HTAN_Parent_Data_File_ID'] = l2_csv.reset_index().set_index('HTAN Biospecimen ID').loc[m3.HTAN_BIOSPECIMEN_ID, 'HTAN Data File ID'].values

		### localize count matrix
		print("Start generate checkSum for count matrix of each sample")
		print(print_time())
		m3["Mtx_tendig_checkSum"] = ""
		for i in m3["FILE_NAME"]:
			fn = "~{sctk_output_dir}/" + m3.loc[m3["FILE_NAME"] == i, "FILE_NAME"].values
			sample = m3.loc[m3["FILE_NAME"] == i,].index.values[0]
			print(fn[0])

			mtx_md5 = calculate_md5sum(fn[0])
			m3.loc[m3["FILE_NAME"] == i, 'Mtx_tendig_checkSum'] = str(int(mtx_md5, base=16))[-10:]
		print(print_time())

		### generate checkSum for each count matrix
		print("Start generating checkSum for each matrix")
		print(print_time())
		m3['HTAN_Data_File_ID'] = m3['HTAN_patient_ID'] + "_" + m3['Mtx_tendig_checkSum']
		print(print_time())

		c = ["Component",
		"Filename",
		"File Format",
		"HTAN Parent Data File ID",
		"HTAN Data File ID",
		"Data Category",
		"Matrix Type",
		"Linked Matrices",
		"Cell Median Number Reads",
		"Cell Median Number Genes",
		"Cell Total",
		"scRNAseq Workflow Type",
		"scRNAseq Workflow Parameters Description",
		"Workflow Link",
		"Workflow Version",
		"Workflow Start Datetime",
		"Workflow End Datetime",
		"HTAN Biospecimen ID"
		]

		x = [[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]

		l3_csv = pd.DataFrame(x, index = c)
		l3_csv = l3_csv.transpose()
		
		l3_csv['Filename'] = m3['FILE_NAME']
		l3_csv['HTAN Parent Data File ID'] = m3['HTAN_Parent_Data_File_ID']
		l3_csv['HTAN Data File ID'] = m3['HTAN_Data_File_ID']
		l3_csv['Matrix Type'] = m3["FILE_NAME"].apply(lambda x: "Normalized Counts" if bool(re.match(r"[\w\d-]+_decontXcounts.mtx.gz", os.path.basename(x))) else "Raw Counts")

		for i in m3["HTAN_BIOSPECIMEN_ID"]:
			allmat = m3.loc[m3["HTAN_BIOSPECIMEN_ID"] == i, 'HTAN_Data_File_ID']
			allmat = [str(i) for i in allmat]
			m3.loc[m3["HTAN_BIOSPECIMEN_ID"] == i, 'Link Matrix'] = ','.join(allmat)

		l3_csv['Linked Matrices'] = m3.reset_index().set_index('FILE_NAME').loc[l3_csv.Filename, 'Link Matrix'].values

		l3_csv['Cell Median Number Reads'] = m3['CELL_MEDIAN_NUM_READS'].values
		l3_csv['Cell Median Number Genes'] = m3['CELL_MEDIAN_NUM_GENES'].values
		l3_csv['Cell Total'] = m3['CELL_TOTAL'].values

		l3_csv['scRNAseq Workflow Type'] = m3["WORKFLOW_TYPE"].values
		l3_csv['scRNAseq Workflow Parameters Description'] = m3["WORKFLOW_PARAMETERS"].values
		l3_csv['Workflow Version'] = m3["WORKFLOW_VERSION"].values
		l3_csv['Component'] = "ScRNA-seqLevel3"
		l3_csv['File Format'] = "mtx"
		l3_csv['Data Category'] = "Gene Expression Quantification"
		l3_csv['Workflow Link'] = "http://sctk.camplab.net/v2.2.0/index.html"
		l3_csv['HTAN Biospecimen ID'] = m3["HTAN_BIOSPECIMEN_ID"].values

		l3_csv.to_csv("HTAN_level3_manifest.csv",sep=",", index=False, header=True)
		os.system("gsutil -q -m cp HTAN_level3_manifest.csv ~{output_dir}")
		print("Output level3 manifest file done")

		CODE
		#gsutil -q -m cp HTAN_level3_manifest.csv '~{output_dir}' .
		#echo "Done copying the level3 manifest file outside python script"
		ls ./* >> level3_ls.txt

	}

	output {
		File? l3_tmp = "./level3_ls.txt"
		File? level3_manifest = "~{output_dir}/HTAN_level3_manifest.csv"
	}

	runtime {
		# Use this container, pull from DockerHub   
		docker: sctk_docker
		cpu: num_cpu
		memory: memory
		disks: "local-disk ~{disk_space} HDD"
		bootDiskSizeGb: 50
		preemptible: 2    
	} 	
}

task generate_level4_meta {
	input {
		File? level3_meta
		File sample_sheet
		String sctk_output_dir
		String output_dir
		Int num_cpu
		String memory
		Int disk_space
		String sctk_docker = "campbio/sctk_qc:2.2.0"
		File? tmp

	}

	command {
		echo $(date +%T)
		gsutil -q -m cp '~{sample_sheet}' .
		echo "Done copying the sample sheet"
		echo $(date +%T) 
		gsutil -q -m cp '~{level3_meta}' .
		echo "Done copying the level3 manifest file"

		python3 <<CODE
		import pandas as pd
		import numpy as np
		import os
		import hashlib
		import re
		from datetime import datetime

		def calculate_md5sum(path):
			os.system("gsutil hash -h %s > md5sum.txt" % (path))
			f = open('md5sum.txt', 'r')

			for line in f:
				line = line.strip()
				line = line.split()
				if line[1] == '(md5):':
					md5sum = line[2]
					return md5sum

		def print_time():
			dateTimeObj = datetime.now()
			return dateTimeObj

		print("Start generating level4 manifest file")
		print(print_time())

		sp = os.path.basename('~{sample_sheet}')
		lp = os.path.basename('~{level3_meta}')

		samplesheet = pd.read_csv(sp)
		l3_csv = pd.read_csv(lp)

		### read all level3 meta files generated by SCTK-QC
		print("Start loading all level4 meta data generated by SCTK-QC")
		print(print_time())
		m4_list = dict()
		for s in samplesheet["Sample"]:
			fp = "~{sctk_output_dir}/" + s + "_QCOut"
			print(fp)

			### need to localize level3 meta files
			#if os.path.isdir(fp):
			os.system("mkdir %s" % (s))
			fn = fp + "/" + "level4Meta.csv"
			os.system("gsutil -q -m cp %s ./%s" % (fn, s))
			f = pd.read_csv("%s/level4Meta.csv" % (s), index_col = 0)
			m4_list[s] = f

		print(m4_list.keys())
		m4 = pd.concat(m4_list)
		m4
		print(print_time())

		samplesheet = samplesheet.set_index('Sample')
		m4 = m4.set_index('SAMPLE')

		### generate HTAN Parent File ID
		m4["HTAN_PARENT_FILE_ID"] = l3_csv.reset_index().set_index('Filename').loc[m4.HTAN_PARENT_FILE_ID, 'HTAN Data File ID'].values

		samplesheet['HTAN_patient_ID'] = samplesheet['HTAN_Parent_Biospecimen_ID'].apply(lambda x: "_".join(x.split("_")[:2]))
		m4['HTAN_patient_ID'] = samplesheet.loc[m4.index, 'HTAN_patient_ID']
		m4['HTAN_BIOSPECIMEN_ID'] = samplesheet.loc[m4.index, 'HTAN_Parent_Biospecimen_ID'].values

		l3_csv['HTAN_patient_ID'] = l3_csv['HTAN Data File ID'].apply(lambda x: "_".join(x.split("_")[:2]))
		l3_csv = l3_csv.set_index('HTAN_patient_ID')

		### localize level4 files
		print("Start generate checkSum for level4 files of each sample")
		print(print_time())
		m4["File_tendig_checkSum"] = ""
		for i in m4["FILE_NAME"]:
			fn = "~{sctk_output_dir}/" + m4.loc[m4["FILE_NAME"] == i, "FILE_NAME"].values
			sample = m4.loc[m4["FILE_NAME"] == i,].index.values[0]

			file_md5 = calculate_md5sum(fn[0])
			m4.loc[m4["FILE_NAME"] == i, 'File_tendig_checkSum'] = str(int(file_md5, base=16))[-10:]

		print(print_time())

		### generate checkSum for each count matrix
		print("Start generating checkSum for each matrix")
		print(print_time())
		m4['HTAN_Data_File_ID'] = m4['HTAN_patient_ID'] + "_" + m4['File_tendig_checkSum']
		print(print_time())

		c = ["Component",
		"Filename",
		"File Format",
		"HTAN Parent Data File ID",
		"HTAN Data File ID",
		"scRNAseq Workflow Type",
		"scRNAseq Workflow Parameters Description",
		"Workflow Version",
		"Workflow Link",
		"Workflow Start Datetime",
		"Workflow End Datetime",
		"HTAN Biospecimen ID"]

		x = [[],[],[],[],[],[],[],[],[],[],[]]

		l4_csv = pd.DataFrame(x, index = c)
		l4_csv = l4_csv.transpose()

		l4_csv['Filename'] = m4['FILE_NAME'].values
		l4_csv['HTAN Parent Data File ID'] = m4['HTAN_PARENT_FILE_ID'].values
		l4_csv['HTAN Data File ID'] = m4['HTAN_Data_File_ID'].values
		l4_csv['scRNAseq Workflow Type'] = m4['WORKFLOW_TYPE'].values
		l4_csv['scRNAseq Workflow Parameters Description'] = m4['WORKFLOW_PARAMETERS'].values
		l4_csv['Workflow Version'] = m4['WORKFLOW_VERSION'].values

		l4_csv['Component'] = "ScRNA-seqLevel4"
		l4_csv['File Format'] = "txt"
		l4_csv['Workflow Link'] = "http://sctk.camplab.net/v2.2.0/index.html"
		l4_csv['HTAN Biospecimen ID'] = m4['HTAN_BIOSPECIMEN_ID'].values

		l4_csv.to_csv("HTAN_level4_manifest.csv",sep=",", index=False, header=True)
		os.system("gsutil -q -m cp HTAN_level4_manifest.csv ~{output_dir}")
		print("Output level4 manifest file done")	
		CODE
		#gsutil -q -m cp HTAN_level4_manifest.csv '~{output_dir}' .
		#echo "Done copying the level4 manifest file outside python script"
	}

	output {
		File? level4_manifest = "~{output_dir}/HTAN_level4_manifest.csv"
	}

	runtime {
		# Use this container, pull from DockerHub   
		docker: sctk_docker
		cpu: num_cpu
		memory: memory
		disks: "local-disk ~{disk_space} HDD"
		bootDiskSizeGb: 50
		preemptible: 2    
	} 	
}